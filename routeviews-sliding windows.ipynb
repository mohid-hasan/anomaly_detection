{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132614e7-5841-40f3-a52d-9a0748a3a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGP Anomaly Detection – 8 Models with Sliding Windows – REWRITTEN VERSION\n",
      "==========================================================================================\n",
      "\n",
      "=== SLAMMER (Window Size: 10) ===\n",
      "Original Samples: 7,188 | Anomalies: 796 (11.074%)\n",
      "After Windows: 7,179 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model ROC-AUC PR-AUC Accuracy F1-Score TP FP FN TN Threshold\n",
      "--------------------------------------------------------------------------------\n",
      "CNN           0.6754 0.3012 0.852832 0.346392  84 163 154  1753 0.161785\n",
      "RNN-GRU       0.6803 0.2804 0.837512 0.291498  72 184 166  1732 0.248970\n",
      "LSTM          0.6891 0.2994 0.867688 0.303178  62 109 176  1807 0.290225\n",
      "Bi-GRU        0.6837 0.2710 0.866295 0.304348  63 113 175  1803 0.323831\n",
      "Bi-LSTM       0.6652 0.2435 0.808264 0.276708  79 254 159  1662 0.167703\n",
      "BLS           0.5934 0.1532 0.715413 0.236613  95 470 143  1446 0.542389\n",
      "VFBLS         0.5939 0.1577 0.715877 0.236908  95 469 143  1447 0.538934\n",
      "GBDT-LightGBM 0.6082 0.1738 0.504178 0.229437 159 989  79   927 0.003792\n",
      "\n",
      "Training time (seconds):\n",
      " CNN           32.413s\n",
      " RNN-GRU       13.282s\n",
      " LSTM          16.434s\n",
      " Bi-GRU        41.039s\n",
      " Bi-LSTM       34.547s\n",
      " BLS           0.084s\n",
      " VFBLS         0.113s\n",
      " GBDT-LightGBM 2.634s\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "=== MOSCOW_BLACKOUT (Window Size: 10) ===\n",
      "Original Samples: 6,995 | Anomalies: 831 (11.880%)\n",
      "After Windows: 6,986 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model ROC-AUC PR-AUC Accuracy F1-Score TP FP FN TN Threshold\n",
      "--------------------------------------------------------------------------------\n",
      "CNN           0.9464 0.8044 0.953721 0.785872 178  26  71  1821 0.546355\n",
      "RNN-GRU       0.9324 0.7886 0.941317 0.745342 180  54  69  1793 0.343308\n",
      "LSTM          0.9187 0.7658 0.936546 0.711497 164  48  85  1799 0.322049\n",
      "Bi-GRU        0.9541 0.8654 0.954676 0.806517 198  44  51  1803 0.574380\n",
      "Bi-LSTM       0.9500 0.8450 0.958969 0.820084 196  33  53  1814 0.385439\n",
      "BLS           0.5732 0.1648 0.580630 0.242894 141 771 108  1076 0.532159\n",
      "VFBLS         0.5739 0.1682 0.584447 0.243267 140 762 109  1085 0.527047\n",
      "GBDT-LightGBM 0.6120 0.2216 0.648378 0.257805 128 616 121  1231 0.007729\n",
      "\n",
      "Training time (seconds):\n",
      " CNN           31.763s\n",
      " RNN-GRU       16.894s\n",
      " LSTM          14.607s\n",
      " Bi-GRU        41.265s\n",
      " Bi-LSTM       37.769s\n",
      " BLS           0.088s\n",
      " VFBLS         0.100s\n",
      " GBDT-LightGBM 2.722s\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "=== WANNACRYPT (Window Size: 10) ===\n",
      "Original Samples: 11,520 | Anomalies: 15 (0.130%)\n",
      "After Windows: 11,511 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model ROC-AUC PR-AUC Accuracy F1-Score TP FP FN TN Threshold\n",
      "--------------------------------------------------------------------------------\n",
      "CNN           0.4738 0.0013 0.251303 0.003084   4 2586   0   864 0.000007\n",
      "RNN-GRU       0.6449 0.0134 0.993341 0.080000   1  20   3  3430 0.015884\n",
      "LSTM          0.7280 0.0446 0.997684 0.200000   1   5   3  3445 0.017559\n",
      "Bi-GRU        0.5657 0.0158 0.994499 0.095238   1  16   3  3434 0.017600\n",
      "Bi-LSTM       0.5456 0.0015 0.385061 0.003752   4 2124   0  1326 0.000661\n",
      "BLS           0.7011 0.0333 0.997105 0.166667   1   7   3  3443 0.530699\n",
      "VFBLS         0.6641 0.0270 0.996526 0.142857   1   9   3  3441 0.533410\n",
      "GBDT-LightGBM 0.5175 0.0071 0.987261 0.043478   1  41   3  3409 0.000004\n",
      "\n",
      "Training time (seconds):\n",
      " CNN           48.508s\n",
      " RNN-GRU       27.118s\n",
      " LSTM          25.336s\n",
      " Bi-GRU        64.849s\n",
      " Bi-LSTM       56.628s\n",
      " BLS           0.107s\n",
      " VFBLS         0.135s\n",
      " GBDT-LightGBM 1.068s\n",
      "\n",
      "==========================================================================================\n",
      "Finished. Usual winners: Bi-GRU ≈ Bi-LSTM > CNN > others | Fastest: VFBLS (<0.05s)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BGP Anomaly Detection – 8 Models with Sliding Windows – REWRITTEN VERSION\n",
    "# Models: CNN → RNN-GRU → LSTM → Bi-GRU → Bi-LSTM → BLS → VFBLS → GBDT-LightGBM\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "# Auto-install missing packages\n",
    "def install(p):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p, \"--quiet\"],\n",
    "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "for p in ['lightgbm', 'torch', 'scikit-learn']:\n",
    "    try:\n",
    "        __import__(p.replace('-', '_'))\n",
    "    except:\n",
    "        install(p)\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, confusion_matrix, average_precision_score\n",
    "\n",
    "# Sigmoid for VFBLS/BLS\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "# ReLU for BLS\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "datasets = {\n",
    "    'Slammer': 'Slammer.csv',\n",
    "    'Moscow_blackout': 'Moscow_blackout.csv',\n",
    "    'WannaCrypt': 'WannaCrypt.csv'\n",
    "}\n",
    "\n",
    "# ============================= PyTorch Models =============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(d, 64, batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(h.squeeze(0)).view(-1)\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, d, h=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(d, h, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(h*2, 64), nn.ReLU(), nn.Dropout(drop), nn.Linear(64, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        h = torch.cat((h[0], h[1]), dim=1)\n",
    "        return self.fc(h).view(-1)\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(d, 64, batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h.squeeze(0)).view(-1)\n",
    "\n",
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, d, h=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(d, h, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(h*2, 64), nn.ReLU(), nn.Dropout(drop), nn.Linear(64, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        h = torch.cat((h[0], h[1]), dim=1)\n",
    "        return self.fc(h).view(-1)\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(d, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1), nn.Flatten(),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return self.net(x).view(-1)\n",
    "\n",
    "# ============================= VFBLS (correct & fast) =============================\n",
    "def train_vf_bls(X, y, C=1e-8, s=0.8, enh=80):\n",
    "    y = y.reshape(-1, 1)\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Wf = np.linalg.pinv(Xb.T @ Xb + C * np.eye(Xb.shape[1])) @ (Xb.T @ y)\n",
    "    Z = Xb @ Wf\n",
    "    We = np.random.randn(Z.shape[1], enh)\n",
    "    H = np.tanh(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    Wo = np.linalg.pinv(A.T @ A + C * np.eye(A.shape[1])) @ (A.T @ y)\n",
    "    return Wf, We, Wo, s\n",
    "\n",
    "def predict_vfbls(X, params):\n",
    "    Wf, We, Wo, s = params\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Z = Xb @ Wf\n",
    "    H = np.tanh(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    return sigmoid(A @ Wo).flatten()\n",
    "\n",
    "# ============================= BLS =============================\n",
    "def train_bls(X, y, C=1e-8, s=0.8, enh=80):\n",
    "    y = y.reshape(-1, 1)\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Wf = np.linalg.pinv(Xb.T @ Xb + C * np.eye(Xb.shape[1])) @ (Xb.T @ y)\n",
    "    Z = Xb @ Wf\n",
    "    We = np.random.randn(Z.shape[1], enh)\n",
    "    H = relu(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    Wo = np.linalg.pinv(A.T @ A + C * np.eye(A.shape[1])) @ (A.T @ y)\n",
    "    return Wf, We, Wo, s\n",
    "\n",
    "def predict_bls(X, params):\n",
    "    Wf, We, Wo, s = params\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Z = Xb @ Wf\n",
    "    H = relu(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    return sigmoid(A @ Wo).flatten()\n",
    "\n",
    "# ============================= Evaluation =============================\n",
    "def evaluate(p, y):\n",
    "    p = np.clip(p, 1e-8, 1-1e-8)\n",
    "    if y.sum() == 0 or (y == 0).sum() == 0:\n",
    "        return {'ROC-AUC':'N/A','PR-AUC':'N/A','Accuracy':'0.000000','F1-Score':'0.000000',\n",
    "                'TP':0,'FP':0,'FN':0,'TN':0,'Threshold':'0.500000'}\n",
    "    try:\n",
    "        prec, rec, thr = precision_recall_curve(y, p)\n",
    "        f1 = 2*prec*rec/(prec+rec+1e-12)\n",
    "        idx = np.argmax(f1)\n",
    "        thr_val = thr[idx] if len(thr) > idx else 0.5\n",
    "        pred = (p >= thr_val).astype(int)\n",
    "        f1_val = f1[idx]\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred, labels=[0,1]).ravel()\n",
    "        return {\n",
    "            'ROC-AUC': f'{roc_auc_score(y,p):.4f}',\n",
    "            'PR-AUC': f'{average_precision_score(y,p):.4f}',\n",
    "            'Accuracy': f'{(tp+tn)/len(y):.6f}',\n",
    "            'F1-Score': f'{f1_val:.6f}',\n",
    "            'TP':int(tp), 'FP':int(fp), 'FN':int(fn), 'TN':int(tn),\n",
    "            'Threshold': f'{thr_val:.6f}'\n",
    "        }\n",
    "    except:\n",
    "        return {'ROC-AUC':'N/A','PR-AUC':'N/A','Accuracy':'0.000000','F1-Score':'0.000000',\n",
    "                'TP':0,'FP':0,'FN':0,'TN':0,'Threshold':'0.500000'}\n",
    "\n",
    "def create_sliding_windows(X, y, window_size):\n",
    "    num_samples = len(X) - window_size + 1\n",
    "    if num_samples <= 0:\n",
    "        raise ValueError(\"Window size larger than data length\")\n",
    "    X_windows = np.zeros((num_samples, window_size, X.shape[1]), dtype=np.float32)\n",
    "    y_windows = np.zeros(num_samples, dtype=int)\n",
    "    for i in range(num_samples):\n",
    "        X_windows[i] = X[i:i + window_size]\n",
    "        y_windows[i] = y[i + window_size - 1]  # Label from end of window\n",
    "    return X_windows, y_windows\n",
    "\n",
    "# ============================= Main =============================\n",
    "window_size = 10  # As per paper, test 1-300; start with 10\n",
    "print(\"BGP Anomaly Detection – 8 Models with Sliding Windows – REWRITTEN VERSION\")\n",
    "print(\"=\"*90)\n",
    "for ds_name, path in datasets.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"{path} not found → skipping {ds_name}\")\n",
    "        continue\n",
    "    print(f\"\\n=== {ds_name.upper()} (Window Size: {window_size}) ===\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    y = (df[3] != 0).astype(int).values\n",
    "    X = df.iloc[:, 4:41].astype(np.float32).values  # 37 features as per paper\n",
    "    print(f\"Original Samples: {len(y):,} | Anomalies: {y.sum():,} ({y.mean()*100:.3f}%)\")\n",
    "    X = SimpleImputer(strategy='median').fit_transform(X)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_seq, y_seq = create_sliding_windows(X, y, window_size)\n",
    "    print(f\"After Windows: {len(y_seq):,} samples\")\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42, stratify=y_seq)\n",
    "    tr_tensor = torch.FloatTensor(X_tr)  # [batch, seq, features]\n",
    "    te_tensor = torch.FloatTensor(X_te)\n",
    "    loader = DataLoader(TensorDataset(tr_tensor, torch.FloatTensor(y_tr)), batch_size=64, shuffle=True)\n",
    "    results = {}\n",
    "    times = {}\n",
    "    # GBDT-LightGBM (flatten sequences)\n",
    "    X_tr_flat = X_tr.reshape(X_tr.shape[0], -1)\n",
    "    X_te_flat = X_te.reshape(X_te.shape[0], -1)\n",
    "    t0 = time.time()\n",
    "    gbm = lgb.train({'objective':'binary','verbose':-1}, lgb.Dataset(X_tr_flat, y_tr), num_boost_round=300)\n",
    "    results['GBDT-LightGBM'] = gbm.predict(X_te_flat)\n",
    "    times['GBDT-LightGBM'] = time.time() - t0\n",
    "    # Neural nets in requested sequence\n",
    "    for name, cls, epochs in [\n",
    "        ('CNN', CNN1DModel, 12),\n",
    "        ('RNN-GRU', GRUModel, 12),\n",
    "        ('LSTM', LSTMModel, 12),\n",
    "        ('Bi-GRU', BiGRUModel, 15),\n",
    "        ('Bi-LSTM', BiLSTMModel, 15)\n",
    "    ]:\n",
    "        t0 = time.time()\n",
    "        model = cls(X_tr.shape[2])\n",
    "        opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.BCELoss()\n",
    "        model.train()\n",
    "        for _ in range(epochs):\n",
    "            for bx, by in loader:\n",
    "                opt.zero_grad()\n",
    "                loss = criterion(model(bx).view(-1), by)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            results[name] = model(te_tensor).cpu().numpy().flatten()\n",
    "        times[name] = time.time() - t0\n",
    "    # BLS (flatten)\n",
    "    t0 = time.time()\n",
    "    params = train_bls(X_tr_flat, y_tr)\n",
    "    results['BLS'] = predict_bls(X_te_flat, params)\n",
    "    times['BLS'] = time.time() - t0\n",
    "    # VFBLS (flatten)\n",
    "    t0 = time.time()\n",
    "    params = train_vf_bls(X_tr_flat, y_tr)\n",
    "    results['VFBLS'] = predict_vfbls(X_te_flat, params)\n",
    "    times['VFBLS'] = time.time() - t0\n",
    "    # Results\n",
    "    model_order = ['CNN', 'RNN-GRU', 'LSTM', 'Bi-GRU', 'Bi-LSTM', 'BLS', 'VFBLS', 'GBDT-LightGBM']\n",
    "    print(\"\\nResearch Mode (optimal F1 threshold)\")\n",
    "    print(\"Model ROC-AUC PR-AUC Accuracy F1-Score TP FP FN TN Threshold\")\n",
    "    print(\"-\"*80)\n",
    "    for m in model_order:\n",
    "        e = evaluate(results[m], y_te)\n",
    "        print(f\"{m:<13} {e['ROC-AUC']} {e['PR-AUC']} {e['Accuracy']} {e['F1-Score']} {e['TP']:>3} {e['FP']:>3} {e['FN']:>3} {e['TN']:>5} {e['Threshold']}\")\n",
    "    print(\"\\nTraining time (seconds):\")\n",
    "    for m in model_order:\n",
    "        print(f\" {m:<13} {times[m]:.3f}s\")\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "print(\"Finished. Usual winners: Bi-GRU ≈ Bi-LSTM > CNN > others | Fastest: VFBLS (<0.05s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565e398-d24b-4411-a9e0-d15946bdf196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
