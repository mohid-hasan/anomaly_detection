{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c29e321-0e39-4fa6-8b9e-6f90f229772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IODA Anomaly Detection with Sliding Windows – CNN, RNN-GRU, LSTM, Bi-GRU, Bi-LSTM, BLS, VFBLS, GBDT-LightGBM\n",
      "==========================================================================================\n",
      "\n",
      "=== ZHYTOMYR (Window Size: 10) ===\n",
      "Original Samples: 923 | Anomalies: 289 (31.311%)\n",
      "Selected 1 features\n",
      "After Windows: 914 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model           ROC-AUC PR-AUC Accuracy F1-Score TP  FP  FN   TN   Threshold Precision Sensitivity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CNN             0.6213  0.4451 0.527473 0.509506  67 110  19   77 0.326425 0.378531 0.779070\n",
      "RNN-GRU         0.5629  0.3306 0.527473 0.513208  68 111  18   76 0.346366 0.379888 0.790698\n",
      "LSTM            0.5760  0.3770 0.516484 0.514706  70 116  16   71 0.240081 0.376344 0.813953\n",
      "Bi-GRU          0.5709  0.3616 0.538462 0.522727  69 109  17   78 0.327392 0.387640 0.802326\n",
      "Bi-LSTM         0.5756  0.3781 0.523810 0.511278  68 112  18   75 0.399610 0.377778 0.790698\n",
      "BLS             0.5376  0.3211 0.523810 0.522059  71 115  15   72 0.575973 0.381720 0.825581\n",
      "VFBLS           0.5419  0.3221 0.523810 0.522059  71 115  15   72 0.560444 0.381720 0.825581\n",
      "GBDT-LightGBM   0.8018  0.6028 0.758242 0.670000  67  47  19  140 0.135169 0.587719 0.779070\n",
      "\n",
      "Training time (seconds):\n",
      " CNN             1.039s\n",
      " RNN-GRU         0.784s\n",
      " LSTM            0.795s\n",
      " Bi-GRU          1.723s\n",
      " Bi-LSTM         1.874s\n",
      " BLS             0.005s\n",
      " VFBLS           0.007s\n",
      " GBDT-LightGBM   0.172s\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "=== IRAQ (Window Size: 10) ===\n",
      "Original Samples: 2,928 | Anomalies: 489 (16.701%)\n",
      "Selected 3 features\n",
      "After Windows: 2,919 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model           ROC-AUC PR-AUC Accuracy F1-Score TP  FP  FN   TN   Threshold Precision Sensitivity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CNN             0.9968  0.9788 0.977143 0.933775 141  15   5  714 0.261332 0.903846 0.965753\n",
      "RNN-GRU         0.9960  0.9148 0.977143 0.933775 141  15   5  714 0.160691 0.903846 0.965753\n",
      "LSTM            0.9969  0.9787 0.977143 0.933775 141  15   5  714 0.286251 0.903846 0.965753\n",
      "Bi-GRU          0.9984  0.9853 0.981714 0.947368 144  14   2  715 0.454867 0.911392 0.986301\n",
      "Bi-LSTM         0.9961  0.9549 0.974857 0.926667 139  15   7  714 0.447736 0.902597 0.952055\n",
      "BLS             0.9945  0.9675 0.965714 0.902597 139  23   7  706 0.558985 0.858025 0.952055\n",
      "VFBLS           0.9951  0.9703 0.968000 0.908497 139  21   7  708 0.594879 0.868750 0.952055\n",
      "GBDT-LightGBM   1.0000  0.9932 1.000000 1.000000 146   0   0  729 0.946234 1.000000 1.000000\n",
      "\n",
      "Training time (seconds):\n",
      " CNN             3.986s\n",
      " RNN-GRU         2.267s\n",
      " LSTM            2.187s\n",
      " Bi-GRU          5.166s\n",
      " Bi-LSTM         5.342s\n",
      " BLS             0.010s\n",
      " VFBLS           0.011s\n",
      " GBDT-LightGBM   0.120s\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "=== GAZA (Window Size: 10) ===\n",
      "Original Samples: 3,359 | Anomalies: 421 (12.533%)\n",
      "Selected 2 features\n",
      "After Windows: 3,350 samples\n",
      "\n",
      "Research Mode (optimal F1 threshold)\n",
      "Model           ROC-AUC PR-AUC Accuracy F1-Score TP  FP  FN   TN   Threshold Precision Sensitivity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CNN             0.9708  0.7325 0.946215 0.802920 110  38  16  840 0.549957 0.743243 0.873016\n",
      "RNN-GRU         0.9736  0.7424 0.946215 0.802920 110  38  16  840 0.498780 0.743243 0.873016\n",
      "LSTM            0.9741  0.7435 0.947211 0.805861 110  37  16  841 0.591910 0.748299 0.873016\n",
      "Bi-GRU          0.9743  0.7429 0.947211 0.807273 111  38  15  840 0.532317 0.744966 0.880952\n",
      "Bi-LSTM         0.9743  0.7424 0.942231 0.800000 116  48  10  830 0.463736 0.707317 0.920635\n",
      "BLS             0.9697  0.7415 0.944223 0.795620 109  39  17  839 0.616019 0.736486 0.865079\n",
      "VFBLS           0.9690  0.7754 0.945219 0.798535 109  38  17  840 0.623400 0.741497 0.865079\n",
      "GBDT-LightGBM   0.9793  0.8087 0.947211 0.816609 118  45   8  833 0.064415 0.723926 0.936508\n",
      "\n",
      "Training time (seconds):\n",
      " CNN             3.682s\n",
      " RNN-GRU         2.328s\n",
      " LSTM            2.489s\n",
      " Bi-GRU          6.059s\n",
      " Bi-LSTM         6.302s\n",
      " BLS             0.006s\n",
      " VFBLS           0.008s\n",
      " GBDT-LightGBM   0.130s\n",
      "\n",
      "==========================================================================================\n",
      "Finished. Usual winners: Bi-GRU ≈ Bi-LSTM > CNN > others | Fastest: VFBLS / BLS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "# Auto-install missing packages\n",
    "def install(p):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p, \"--quiet\"],\n",
    "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "for p in ['lightgbm', 'torch', 'scikit-learn']:\n",
    "    try:\n",
    "        __import__(p.replace('-', '_'))\n",
    "    except:\n",
    "        install(p)\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Sigmoid for VFBLS\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "# ReLU for BLS\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "datasets = {\n",
    "    'Zhytomyr': 'ioda_region_4369_zhytomyr.csv',\n",
    "    'Iraq': 'ioda_country_IQ_iraq.csv',\n",
    "    'Gaza': 'ioda_region_1226_gazastrip.csv'\n",
    "}\n",
    "\n",
    "# PyTorch Models\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, d, seq_len):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(d, 64, batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(h.squeeze(0)).view(-1)\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, d, seq_len, h=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(d, h, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(h*2, 64), nn.ReLU(), nn.Dropout(drop), nn.Linear(64, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        h = torch.cat((h[0], h[1]), dim=1)\n",
    "        return self.fc(h).view(-1)\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, d, seq_len):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(d, 64, batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h.squeeze(0)).view(-1)\n",
    "\n",
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, d, seq_len, h=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(d, h, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(h*2, 64), nn.ReLU(), nn.Dropout(drop), nn.Linear(64, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        h = torch.cat((h[0], h[1]), dim=1)\n",
    "        return self.fc(h).view(-1)\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, d, seq_len):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(d, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1), nn.Flatten(),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [batch, features, seq_len] for Conv1d\n",
    "        return self.net(x).view(-1)\n",
    "\n",
    "# VFBLS\n",
    "def train_vf_bls(X, y, C=1e-8, s=0.8, enh=80):\n",
    "    y = y.reshape(-1, 1)\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Wf = np.linalg.pinv(Xb.T @ Xb + C * np.eye(Xb.shape[1])) @ (Xb.T @ y)\n",
    "    Z = Xb @ Wf\n",
    "    We = np.random.randn(Z.shape[1], enh)\n",
    "    H = np.tanh(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    Wo = np.linalg.pinv(A.T @ A + C * np.eye(A.shape[1])) @ (A.T @ y)\n",
    "    return Wf, We, Wo, s\n",
    "\n",
    "def predict_vfbls(X, params):\n",
    "    Wf, We, Wo, s = params\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Z = Xb @ Wf\n",
    "    H = np.tanh(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    return sigmoid(A @ Wo).flatten()\n",
    "\n",
    "# BLS (basic version with ReLU for enhancement)\n",
    "def train_bls(X, y, C=1e-8, s=0.8, enh=80):\n",
    "    y = y.reshape(-1, 1)\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Wf = np.linalg.pinv(Xb.T @ Xb + C * np.eye(Xb.shape[1])) @ (Xb.T @ y)\n",
    "    Z = Xb @ Wf\n",
    "    We = np.random.randn(Z.shape[1], enh)\n",
    "    H = relu(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    Wo = np.linalg.pinv(A.T @ A + C * np.eye(A.shape[1])) @ (A.T @ y)\n",
    "    return Wf, We, Wo, s\n",
    "\n",
    "def predict_bls(X, params):\n",
    "    Wf, We, Wo, s = params\n",
    "    bias = 0.1 * np.ones((X.shape[0], 1))\n",
    "    Xb = np.hstack([X, bias])\n",
    "    Z = Xb @ Wf\n",
    "    H = relu(Z @ We)\n",
    "    A = np.hstack([Z, H]) / s\n",
    "    return sigmoid(A @ Wo).flatten()\n",
    "\n",
    "# Manual imputation (median per column)\n",
    "def manual_impute_median(X):\n",
    "    for j in range(X.shape[1]):\n",
    "        col = X[:, j]\n",
    "        non_nan = col[~np.isnan(col)]\n",
    "        if len(non_nan) > 0:\n",
    "            med = np.median(non_nan)\n",
    "            col[np.isnan(col)] = med\n",
    "    return X\n",
    "\n",
    "# Manual scaling (z-score per column)\n",
    "def manual_scale(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    std[std == 0] = 1  # Avoid division by zero\n",
    "    return (X - mean) / std\n",
    "\n",
    "# Manual stratified train_test_split\n",
    "def manual_stratified_split(X, y, test_size=0.3, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    idx0 = np.where(y == 0)[0]\n",
    "    idx1 = np.where(y == 1)[0]\n",
    "    n_test0 = int(len(idx0) * test_size)\n",
    "    n_test1 = int(len(idx1) * test_size)\n",
    "    test_idx0 = np.random.choice(idx0, n_test0, replace=False)\n",
    "    test_idx1 = np.random.choice(idx1, n_test1, replace=False)\n",
    "    test_idx = np.concatenate([test_idx0, test_idx1])\n",
    "    train_idx = np.setdiff1d(np.arange(len(y)), test_idx)\n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "# Manual confusion matrix\n",
    "def manual_confusion_matrix(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "# Manual ROC AUC\n",
    "def manual_roc_auc_score(y_true, y_score):\n",
    "    idx = np.argsort(y_score)[::-1]\n",
    "    y_true = y_true[idx]\n",
    "    y_score = y_score[idx]\n",
    "    tpr = np.cumsum(y_true) / np.sum(y_true) if np.sum(y_true) > 0 else np.zeros(len(y_true))\n",
    "    fpr = np.cumsum(1 - y_true) / np.sum(1 - y_true) if np.sum(1 - y_true) > 0 else np.zeros(len(y_true))\n",
    "    return np.trapezoid(tpr, fpr)\n",
    "\n",
    "# Manual precision_recall_curve\n",
    "def manual_precision_recall_curve(y_true, y_score):\n",
    "    if len(y_true) == 0:\n",
    "        return np.array([1.0]), np.array([0.0]), np.array([])\n",
    "    idx = np.argsort(y_score)[::-1]\n",
    "    y_true = y_true[idx]\n",
    "    y_score = y_score[idx]\n",
    "    distinct_value_indices = np.where(np.diff(y_score) != 0)[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "    tps = np.cumsum(y_true)[threshold_idxs]\n",
    "    fps = np.cumsum(1 - y_true)[threshold_idxs]\n",
    "    thresholds = y_score[threshold_idxs]\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        prec = tps / (tps + fps)\n",
    "    prec[np.isnan(prec)] = 0.0\n",
    "    rec = tps / np.sum(y_true) if np.sum(y_true) > 0 else np.zeros_like(tps)\n",
    "    return prec, rec, thresholds\n",
    "\n",
    "# Manual average_precision_score\n",
    "def manual_average_precision_score(y_true, y_score):\n",
    "    prec, rec, _ = manual_precision_recall_curve(y_true, y_score)\n",
    "    if len(rec) == 0:\n",
    "        return 0.0\n",
    "    return np.sum(np.diff(rec) * prec[:-1])\n",
    "\n",
    "def evaluate(p, y):\n",
    "    p = np.clip(p, 1e-8, 1-1e-8)\n",
    "    if np.sum(y) == 0 or np.sum(y == 0) == 0:\n",
    "        return {'ROC-AUC':'N/A','PR-AUC':'N/A','Accuracy':'0.000000','F1-Score':'0.000000',\n",
    "                'TP':0,'FP':0,'FN':0,'TN':0,'Threshold':'0.500000','Precision':'0.000000','Sensitivity':'0.000000'}\n",
    "    prec, rec, thr = manual_precision_recall_curve(y, p)\n",
    "    f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "    idx = np.argmax(f1)\n",
    "    thr_val = thr[idx] if len(thr) > idx else 0.5\n",
    "    pred = (p >= thr_val).astype(int)\n",
    "    f1_val = f1[idx]\n",
    "    tp, fp, fn, tn = manual_confusion_matrix(y, pred)\n",
    "    accuracy = (tp + tn) / len(y)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    roc_auc = manual_roc_auc_score(y, p)\n",
    "    pr_auc = manual_average_precision_score(y, p)\n",
    "    return {\n",
    "        'ROC-AUC': f'{roc_auc:.4f}',\n",
    "        'PR-AUC': f'{pr_auc:.4f}',\n",
    "        'Accuracy': f'{accuracy:.6f}',\n",
    "        'F1-Score': f'{f1_val:.6f}',\n",
    "        'TP': int(tp), 'FP': int(fp), 'FN': int(fn), 'TN': int(tn),\n",
    "        'Threshold': f'{thr_val:.6f}',\n",
    "        'Precision': f'{precision:.6f}',\n",
    "        'Sensitivity': f'{sensitivity:.6f}'\n",
    "    }\n",
    "\n",
    "def create_sliding_windows(X, y, window_size):\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        X_windows.append(X[i:i + window_size])\n",
    "        y_windows.append(y[i + window_size - 1])\n",
    "    return np.array(X_windows), np.array(y_windows)\n",
    "\n",
    "# Main\n",
    "window_size = 10  # Configurable, as per paper tested 1-300\n",
    "print(\"IODA Anomaly Detection with Sliding Windows – CNN, RNN-GRU, LSTM, Bi-GRU, Bi-LSTM, BLS, VFBLS, GBDT-LightGBM\")\n",
    "print(\"=\"*90)\n",
    "for ds_name, path in datasets.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"{path} not found → skipping {ds_name}\")\n",
    "        continue\n",
    "    print(f\"\\n=== {ds_name.upper()} (Window Size: {window_size}) ===\")\n",
    "    df = pd.read_csv(path)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')  # Ensure chronological order\n",
    "    df['LABEL'] = 0\n",
    "    if ds_name == 'Zhytomyr':\n",
    "        start = pd.to_datetime('2022-03-21 12:00:00+00:00')\n",
    "        end = pd.to_datetime('2022-03-22 12:00:00+00:00')\n",
    "        df.loc[(df['datetime'] >= start) & (df['datetime'] <= end), 'LABEL'] = 1\n",
    "    elif ds_name == 'Iraq':\n",
    "        for day in range(21, 31):\n",
    "            start = pd.to_datetime(f'2023-08-{day:02d} 01:00:00+00:00')\n",
    "            end = pd.to_datetime(f'2023-08-{day:02d} 05:00:00+00:00')\n",
    "            df.loc[(df['datetime'] >= start) & (df['datetime'] <= end), 'LABEL'] = 1\n",
    "    elif ds_name == 'Gaza':\n",
    "        start = pd.to_datetime('2023-10-27 16:00:00+00:00')\n",
    "        end = pd.to_datetime('2023-10-29 03:00:00+00:00')\n",
    "        df.loc[(df['datetime'] >= start) & (df['datetime'] <= end), 'LABEL'] = 1\n",
    "    y = df['LABEL'].values.astype(int)\n",
    "    if ds_name == 'Iraq':\n",
    "        cols = ['merit-nt', 'bgp', 'ping-slash24', 'gtr-norm']\n",
    "    else:\n",
    "        cols = ['merit-nt', 'bgp', 'ping-slash24']\n",
    "    X = df[cols].values.astype(np.float32)\n",
    "    print(f\"Original Samples: {len(y):,} | Anomalies: {y.sum():,} ({y.mean()*100:.3f}%)\")\n",
    "    X = manual_impute_median(X)\n",
    "    X = manual_scale(X)\n",
    "    # Feature selection before windows\n",
    "    if len(cols) > 1:\n",
    "        selector = ExtraTreesClassifier(n_estimators=50)\n",
    "        selector.fit(X, y)\n",
    "        sfm = SelectFromModel(selector, prefit=True)\n",
    "        X = sfm.transform(X)\n",
    "        num_selected = X.shape[1]\n",
    "        print(f\"Selected {num_selected} features\")\n",
    "    X_seq, y_seq = create_sliding_windows(X, y, window_size)\n",
    "    print(f\"After Windows: {len(y_seq):,} samples\")\n",
    "    X_tr, X_te, y_tr, y_te = manual_stratified_split(X_seq, y_seq)\n",
    "    tr_tensor = torch.FloatTensor(X_tr)  # [batch, seq, features]\n",
    "    te_tensor = torch.FloatTensor(X_te)\n",
    "    loader = DataLoader(TensorDataset(tr_tensor, torch.FloatTensor(y_tr)), batch_size=64, shuffle=True)\n",
    "    results = {}\n",
    "    times = {}\n",
    "    # GBDT-LightGBM (flatten for non-seq model)\n",
    "    X_tr_flat = X_tr.reshape(X_tr.shape[0], -1)\n",
    "    X_te_flat = X_te.reshape(X_te.shape[0], -1)\n",
    "    t0 = time.time()\n",
    "    gbm = lgb.train({'objective':'binary','verbose':-1}, lgb.Dataset(X_tr_flat, y_tr), num_boost_round=300)\n",
    "    results['GBDT-LightGBM'] = gbm.predict(X_te_flat)\n",
    "    times['GBDT-LightGBM'] = time.time() - t0\n",
    "    # Torch models in order\n",
    "    for name, cls, epochs in [\n",
    "        ('CNN', CNN1DModel, 12),\n",
    "        ('RNN-GRU', GRUModel, 12),\n",
    "        ('LSTM', LSTMModel, 12),\n",
    "        ('Bi-GRU', BiGRUModel, 15),\n",
    "        ('Bi-LSTM', BiLSTMModel, 15)\n",
    "    ]:\n",
    "        t0 = time.time()\n",
    "        model = cls(X_tr.shape[2], window_size)\n",
    "        opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.BCELoss()\n",
    "        model.train()\n",
    "        for _ in range(epochs):\n",
    "            for bx, by in loader:\n",
    "                opt.zero_grad()\n",
    "                loss = criterion(model(bx).view(-1), by)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            results[name] = model(te_tensor).cpu().numpy().flatten()\n",
    "        times[name] = time.time() - t0\n",
    "    # BLS (flatten)\n",
    "    t0 = time.time()\n",
    "    params = train_bls(X_tr_flat, y_tr)\n",
    "    results['BLS'] = predict_bls(X_te_flat, params)\n",
    "    times['BLS'] = time.time() - t0\n",
    "    # VFBLS (flatten)\n",
    "    t0 = time.time()\n",
    "    params = train_vf_bls(X_tr_flat, y_tr)\n",
    "    results['VFBLS'] = predict_vfbls(X_te_flat, params)\n",
    "    times['VFBLS'] = time.time() - t0\n",
    "    # Results\n",
    "    model_order = ['CNN', 'RNN-GRU', 'LSTM', 'Bi-GRU', 'Bi-LSTM', 'BLS', 'VFBLS', 'GBDT-LightGBM']\n",
    "    print(\"\\nResearch Mode (optimal F1 threshold)\")\n",
    "    print(\"Model           ROC-AUC PR-AUC Accuracy F1-Score TP  FP  FN   TN   Threshold Precision Sensitivity\")\n",
    "    print(\"-\"*100)\n",
    "    for m in model_order:\n",
    "        if m in results:\n",
    "            e = evaluate(results[m], y_te)\n",
    "            print(f\"{m:<15} {e['ROC-AUC']}  {e['PR-AUC']} {e['Accuracy']} {e['F1-Score']} {e['TP']:>3} {e['FP']:>3} {e['FN']:>3} {e['TN']:>4} {e['Threshold']} {e['Precision']} {e['Sensitivity']}\")\n",
    "    print(\"\\nTraining time (seconds):\")\n",
    "    for m in model_order:\n",
    "        if m in times:\n",
    "            print(f\" {m:<15} {times[m]:.3f}s\")\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "print(\"Finished. Usual winners: Bi-GRU ≈ Bi-LSTM > CNN > others | Fastest: VFBLS / BLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed68e3-67c0-43f0-8765-e4057b860a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
